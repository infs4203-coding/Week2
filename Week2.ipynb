{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471f2cfc",
   "metadata": {},
   "source": [
    "In this document, we introduce a modified iris dataset. This dataset has undergone some changes, including the deletion of certain values and the addition of a nominal feature named <em>petal width</em>. Our primary objective is to demonstrate the processes of data loading, handling missing values, normalizing data, and evaluating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148b39c",
   "metadata": {},
   "source": [
    "## 1.Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a82f6",
   "metadata": {},
   "source": [
    "Access the [Iris](https://archive.ics.uci.edu/dataset/53/iris) dataset from https://archive.ics.uci.edu/, the University of California, Irvine (UCI) Machine Learning Repository. UCI is a well-known online repository that hosts various datasets for machine learning research. This toy dataset is widely used for testing out machine learning algorithms and visualizations.\n",
    "\n",
    "**More Information on the Modified Iris Dataset**: A dataset with 150 instances of iris flowers, each described by four features (<em>sepal length</em>, <em>sepal width</em>, <em>petal length</em>, and <em>petal width</em>) and is assigned to one of three iris species.  The first three features are **numerical** and the last one *petal width* is **nominal** among a value from {0,1,2,3,4}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4535d",
   "metadata": {},
   "source": [
    "## 2.Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ead485",
   "metadata": {},
   "source": [
    "We first import the packages that will be used in this document.\n",
    "\n",
    "1. [Pandas](https://pandas.pydata.org/): Pandas is an open-source Python library widely used for data manipulation, analysis, and cleaning tasks. The central data structure in Pandas is the [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) which provides methods to facilitate the preliminary examination of essential properties, statistical summaries, and a select number of rows for a cursory exploration of the data.\n",
    "\n",
    "2. [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html): MinMaxScaler is a package from scikit-learn (sklearn) used for normalization. It scales the data to a specific range (usually between 0 and 1).\n",
    "\n",
    "3. [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html): StandardScaler is another package from scikit-learn (sklearn) used for normalization. It scales the data to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "4. [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html): train_test_split() is used to split a dataset into training and testing subsets, allowing users to evaluate the performance of machine learning models on unseen data.\n",
    "\n",
    "5. [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics): sklearn.metrics includes performance metrics functions used to evaluate a classifier's performance.\n",
    "\n",
    "These packages will be utilized later in the following tasks for data preprocessing and evaluating the performance of a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8883d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36911cb7",
   "metadata": {},
   "source": [
    "After importing these packages, we can begin to load the dataset. The dataset is stored in the <em>iris_modified.csv</em> file. We will use the [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for loading this file and use [info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) to get an initial overview of the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9539d05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   sepal length in cm  148 non-null    float64\n",
      " 1   sepal width in cm   148 non-null    float64\n",
      " 2   petal length in cm  150 non-null    float64\n",
      " 3   petal width         147 non-null    float64\n",
      " 4   class               150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('iris_modified.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ecdfbe",
   "metadata": {},
   "source": [
    "In this dataset, we observe a total of 150 instances, with each instance containing 5 columns. The first three columns represent the **numerical** values of <em>sepal length</em>, <em>sepal width</em>, and <em>petal length</em>, respectively. The fourth column denotes the **nominal** feature <em>petal width</em> of each instance whose values are among {0,1,2,3,4}. Lastly, the fifth column provides the class label for each instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe271d",
   "metadata": {},
   "source": [
    "We can then get some statistical information on each feature of the dataset by [describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72601010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length in cm  sepal width in cm  petal length in cm  petal width\n",
      "count          148.000000         148.000000          150.000000   147.000000\n",
      "mean             5.831757           3.053378            3.758667     1.476190\n",
      "std              0.819328           0.435096            1.764420     1.206906\n",
      "min              4.300000           2.000000            1.000000     0.000000\n",
      "25%              5.100000           2.800000            1.600000     0.000000\n",
      "50%              5.800000           3.000000            4.350000     2.000000\n",
      "75%              6.400000           3.300000            5.100000     2.000000\n",
      "max              7.900000           4.400000            6.900000     4.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376edc35",
   "metadata": {},
   "source": [
    "Despite there being 150 instances, we only have 148 or 147 values for some features. There definitely exist some missing values. Moreover, the value ranges of features are also different from each other. That means we may normalize the data to achieve a better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52def9",
   "metadata": {},
   "source": [
    "Let's have a look at the first 10 rows of the dataset by [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509eaefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length in cm  sepal width in cm  petal length in cm  petal width  \\\n",
       "0                 5.1                3.5                 1.4          0.0   \n",
       "1                 4.9                3.0                 1.4          0.0   \n",
       "2                 4.7                3.2                 1.3          0.0   \n",
       "3                 4.6                3.1                 1.5          0.0   \n",
       "4                 5.0                3.6                 1.4          0.0   \n",
       "5                 5.4                3.9                 1.7          0.0   \n",
       "6                 4.6                3.4                 1.4          0.0   \n",
       "7                 5.0                3.4                 1.5          0.0   \n",
       "8                 4.4                2.9                 1.4          0.0   \n",
       "9                 4.9                3.1                 1.5          0.0   \n",
       "\n",
       "         class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  \n",
       "5  Iris-setosa  \n",
       "6  Iris-setosa  \n",
       "7  Iris-setosa  \n",
       "8  Iris-setosa  \n",
       "9  Iris-setosa  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397be906",
   "metadata": {},
   "source": [
    "We can see all the detailed information of the first 10 instances, and they all belong to the Iris-setora class. Note that checking the dataset and understanding the properties of it are always necessary before we conduct further steps! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b46995",
   "metadata": {},
   "source": [
    "## 3. Missing Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb4062",
   "metadata": {},
   "source": [
    "As expounded in the lecture, the handling of missing values in the dataset entails two primary approaches: the former entails the removal of all data instances containing missing values, while the latter involves the process of imputation.\n",
    "Regarding the imputation process, it encompasses two distinct strategies: one based on the utilization of aggregate values for all instances, and the other employing class-specific values for imputing missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce38f4",
   "metadata": {},
   "source": [
    "### 3.1. Removal\n",
    "\n",
    "This can be conducted by employing the [Pandas.DataFrames](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) function [dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451e1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deleting = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c87526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   sepal length in cm  143 non-null    float64\n",
      " 1   sepal width in cm   143 non-null    float64\n",
      " 2   petal length in cm  143 non-null    float64\n",
      " 3   petal width         143 non-null    float64\n",
      " 4   class               143 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_deleting.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565ab16",
   "metadata": {},
   "source": [
    "We can see there are 143 instances left after the removal of any instance with a missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14be74",
   "metadata": {},
   "source": [
    "### 3.2. Imputation by all values \n",
    "\n",
    "Utilize the [fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) method to impute missing or NaN values within the DataFrame by replacing them with the respective feature's average computed from all available non-null values.\n",
    "\n",
    "\n",
    "Firstly, we apply the [DataFrame.copy()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html) method to create a new DataFrame, ensuring that any modifications made will not affect the original one. This precautionary step allows us to work with a separate copy, preserving the integrity of the original data for further analysis or comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a30864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impu_all = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c7e45",
   "metadata": {},
   "source": [
    "#### 3.2.1 Impute the numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6318b",
   "metadata": {},
   "source": [
    "We then impute the numerical values by the average of the feature's all values.\n",
    "We use the [DataFrame.iloc[]](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html) method with the [fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) to impute the first three numerical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf5c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impu_all.iloc[:,:3] = df_impu_all.iloc[:,:3].fillna(df_impu_all.iloc[:,:3].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84978aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   sepal length in cm  150 non-null    float64\n",
      " 1   sepal width in cm   150 non-null    float64\n",
      " 2   petal length in cm  150 non-null    float64\n",
      " 3   petal width         147 non-null    float64\n",
      " 4   class               150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_impu_all.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480843a",
   "metadata": {},
   "source": [
    "After printing the information and observing that all the numerical values have been imputed (the Non-Null values increase from 148 to 150), we proceed to handle the missing values in the nominal feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76377773",
   "metadata": {},
   "source": [
    "#### 3.2.2 Impute the nominal features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912a00c",
   "metadata": {},
   "source": [
    "For this task, we will use the [DataFrame.mode()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html) method, which allows us to impute the missing categorical values with the most common one in the corresponding column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f9ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impu_all.iloc[:,3] = df_impu_all.iloc[:,3].fillna(df_impu_all.iloc[:,3].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dfed837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   sepal length in cm  150 non-null    float64\n",
      " 1   sepal width in cm   150 non-null    float64\n",
      " 2   petal length in cm  150 non-null    float64\n",
      " 3   petal width         150 non-null    float64\n",
      " 4   class               150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_impu_all.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc709f4",
   "metadata": {},
   "source": [
    "After conducting the imputations for both numerical and nominal features, we can verify the successful completion of this process by printing the information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c6623",
   "metadata": {},
   "source": [
    "### 3.3. Imputation by class-specific values\n",
    "\n",
    "In this part, we will employ a similar approach to addressing missing or NaN values in another way. Specifically, the missing or NaN values are replaced with the mean or most common of the corresponding feature values within their respective class.\n",
    "\n",
    "To obtain the list of unique classes, we employ the [unique()](https://pandas.pydata.org/docs/reference/api/pandas.unique.html) method. In the following codes, we use a for loop to iterate through each class, and perform the imputation process. We will utilize [DataFrame.loc()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) to confirm conditions and facilitate the imputation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c137f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impu_class = df.copy()\n",
    "cat_list = df_impu_class.iloc[:,4].unique()\n",
    "for cat in cat_list:\n",
    "    #imputate numerical values\n",
    "    df_impu_class.loc[df_impu_class.iloc[:,4]==cat,df_impu_class.columns[:3]] = df_impu_class.loc[df_impu_class.iloc[:,4]==cat,df_impu_class.columns[:3]].fillna(\n",
    "        df_impu_class.loc[df_impu_class.iloc[:,4]==cat,df_impu_class.columns[:3]].mean()\n",
    "    )\n",
    "    #imputate categorical values\n",
    "    df_impu_class.loc[df_impu_class.iloc[:,4]==cat,df_impu_class.columns[3]]= df_impu_class.loc[df_impu_class.iloc[:,4]==cat,df_impu_class.columns[3]].fillna(\n",
    "        df_impu_class.loc[df_impu_class.iloc[:,4]==cat,df_impu_class.columns[3]].mode().iloc[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa3d57ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   sepal length in cm  150 non-null    float64\n",
      " 1   sepal width in cm   150 non-null    float64\n",
      " 2   petal length in cm  150 non-null    float64\n",
      " 3   petal width         150 non-null    float64\n",
      " 4   class               150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_impu_class.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bb5ea",
   "metadata": {},
   "source": [
    "## 4. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27c613",
   "metadata": {},
   "source": [
    "After successfully performing the imputation using class-specific values on the dataset, we will proceed to normalization. Note that normalization can be only applied to numerical features so it is essential to select those columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae8f1a",
   "metadata": {},
   "source": [
    "Before doing normalization, let us have a look again at the dataset by [describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "975b3867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length in cm  sepal width in cm  petal length in cm  petal width\n",
      "count          150.000000         150.000000          150.000000   150.000000\n",
      "mean             5.837374           3.053918            3.758667     1.480000\n",
      "std              0.816055           0.433823            1.764420     1.208027\n",
      "min              4.300000           2.000000            1.000000     0.000000\n",
      "25%              5.100000           2.800000            1.600000     0.000000\n",
      "50%              5.800000           3.000000            4.350000     2.000000\n",
      "75%              6.400000           3.300000            5.100000     2.000000\n",
      "max              7.900000           4.400000            6.900000     4.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_impu_class.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4d540",
   "metadata": {},
   "source": [
    "### 4.1. Max-min normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b47c71",
   "metadata": {},
   "source": [
    "We apply the [MinMaxScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) to achieve the max-min normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0611716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_minmax = df_impu_class.copy()\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_class_minmax.loc[:,df_impu_class.columns[:3]])\n",
    "df_class_minmax.loc[:,df_impu_class.columns[:3]] = scaler.transform(df_class_minmax.loc[:,df_impu_class.columns[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb3155",
   "metadata": {},
   "source": [
    "Let us have a look at the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf36873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length in cm  sepal width in cm  petal length in cm  petal width\n",
      "count          150.000000         150.000000          150.000000   150.000000\n",
      "mean             0.427048           0.439133            0.467571     1.480000\n",
      "std              0.226682           0.180760            0.299054     1.208027\n",
      "min              0.000000           0.000000            0.000000     0.000000\n",
      "25%              0.222222           0.333333            0.101695     0.000000\n",
      "50%              0.416667           0.416667            0.567797     2.000000\n",
      "75%              0.583333           0.541667            0.694915     2.000000\n",
      "max              1.000000           1.000000            1.000000     4.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_class_minmax.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37748ecf",
   "metadata": {},
   "source": [
    "All three numeraical features are now normalized to the range of [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98dcc5",
   "metadata": {},
   "source": [
    "### 4.2. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c140d",
   "metadata": {},
   "source": [
    "We then apply the [StandardScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to achieve the standardization (or z-score normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c95c4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_standard = df_impu_class.copy()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_class_standard.loc[:,df_impu_class.columns[:3]])\n",
    "df_class_standard.loc[:,df_impu_class.columns[:3]] = scaler.transform(df_class_standard.loc[:,df_impu_class.columns[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735906b",
   "metadata": {},
   "source": [
    "We can also have a brief look at the dataset after standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d417707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length in cm  sepal width in cm  petal length in cm  petal width\n",
      "count        1.500000e+02       1.500000e+02        1.500000e+02   150.000000\n",
      "mean         1.421085e-15      -1.586879e-15        3.315866e-16     1.480000\n",
      "std          1.003350e+00       1.003350e+00        1.003350e+00     1.208027\n",
      "min         -1.890220e+00      -2.437514e+00       -1.568735e+00     0.000000\n",
      "25%         -9.066106e-01      -5.872651e-01       -1.227541e+00     0.000000\n",
      "50%         -4.595198e-02      -1.247030e-01        3.362659e-01     2.000000\n",
      "75%          6.917554e-01       5.691402e-01        7.627586e-01     2.000000\n",
      "max          2.536024e+00       3.113232e+00        1.786341e+00     4.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_class_standard.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f98864",
   "metadata": {},
   "source": [
    "Ideally, the mean should be 0 with std to be 1 after z-score normalization. We can round the results to avoid those floating point precision deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49bf34e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length in cm  sepal width in cm  petal length in cm  petal width\n",
      "count              150.00             150.00              150.00       150.00\n",
      "mean                 0.00              -0.00                0.00         1.48\n",
      "std                  1.00               1.00                1.00         1.21\n",
      "min                 -1.89              -2.44               -1.57         0.00\n",
      "25%                 -0.91              -0.59               -1.23         0.00\n",
      "50%                 -0.05              -0.12                0.34         2.00\n",
      "75%                  0.69               0.57                0.76         2.00\n",
      "max                  2.54               3.11                1.79         4.00\n"
     ]
    }
   ],
   "source": [
    "print(df_class_standard.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b366cb",
   "metadata": {},
   "source": [
    "# 5.Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d93f53",
   "metadata": {},
   "source": [
    "Since we don't have a test file, we split the dataset into two subsets: a training set (used for training) and a testing set (used for validating or testing) by [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method. By the default setting, it will create a test set consisting of 25% of the original data. In the current dataset consisting of 150 instances, it will lead to 38 test instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "438ba908",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_class_standard.iloc[:,-1].values\n",
    "X = df_class_standard.iloc[:,0:4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9a1c8",
   "metadata": {},
   "source": [
    "Since we will introduce constructing classifiers from Week 3, we can proceed directly to the evaluation phase using the test results provided. Classifier_A provides a prediction on the test data which is stored in *prediction_1.csv*, and Classifier B provides one in *prediction_2.csv*. In the following, we will evaluate Classifier_B and leave evaluating Classifier_A as optional homework. \n",
    "\n",
    "First, we load the test csv file *prediction_2.csv* and have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6741e023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted class\n",
       "0    Iris-virginica\n",
       "1   Iris-versicolor\n",
       "2       Iris-setosa\n",
       "3    Iris-virginica\n",
       "4       Iris-setosa\n",
       "5    Iris-virginica\n",
       "6       Iris-setosa\n",
       "7   Iris-versicolor\n",
       "8    Iris-virginica\n",
       "9   Iris-versicolor\n",
       "10   Iris-virginica\n",
       "11  Iris-versicolor\n",
       "12  Iris-versicolor\n",
       "13  Iris-versicolor\n",
       "14  Iris-versicolor\n",
       "15      Iris-setosa\n",
       "16  Iris-versicolor\n",
       "17  Iris-versicolor\n",
       "18      Iris-setosa\n",
       "19      Iris-setosa\n",
       "20   Iris-virginica\n",
       "21  Iris-versicolor\n",
       "22      Iris-setosa\n",
       "23      Iris-setosa\n",
       "24   Iris-virginica\n",
       "25      Iris-setosa\n",
       "26      Iris-setosa\n",
       "27  Iris-versicolor\n",
       "28  Iris-versicolor\n",
       "29      Iris-setosa\n",
       "30   Iris-virginica\n",
       "31  Iris-versicolor\n",
       "32      Iris-setosa\n",
       "33   Iris-virginica\n",
       "34   Iris-virginica\n",
       "35  Iris-versicolor\n",
       "36      Iris-setosa\n",
       "37   Iris-virginica"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction_1 = pd.read_csv('prediction_2.csv')\n",
    "df_prediction_1.head(38)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8ffd2",
   "metadata": {},
   "source": [
    "We can observe that the file provides the predicted class, which we will use for evaluation so we select those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec03195",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = df_prediction_1.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa813c",
   "metadata": {},
   "source": [
    "We can then show the accuracy of the classifier by [accuracy_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "009198a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_predict)\n",
    "print(\"The prediction accuracy is: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87286869",
   "metadata": {},
   "source": [
    "Also, we can get the macro f1-score by [metrics.f1_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "210fb24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction macro f1-score is:  0.9444444444444445\n"
     ]
    }
   ],
   "source": [
    "f1 = metrics.f1_score(y_test, y_predict, average='macro')\n",
    "print(\"The prediction macro f1-score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a4686",
   "metadata": {},
   "source": [
    "Please try to evaluate Classifier_A by yourself:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874783e1",
   "metadata": {},
   "source": [
    "Author: *Kaki Zhou* 28/7/2023"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Kaki Zhou"
   },
   {
    "name": "Miao Xu"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
